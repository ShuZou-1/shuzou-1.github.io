<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="This is the file in demostrating SimLabel">
    <title>SimLabel: Consistency-Guided OOD Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- 引入CSS样式 -->
    <link rel="stylesheet" href="styles.css">
    <style>
      /* 定义样式 */
      p{
        font-size: 24px;
      }
      .custom-text {
          font-size: 30px; /* 设置文字大小 */
          font-family: "Arial", sans-serif; /* 设置字体 */
          font-weight: bold; /* 设置字体加粗（可选） */
          color: #333; /* 设置文字颜色 */
          text-align: center; /* 水平居中对齐 */
          padding-top: 25px;
      }
      img {
            display: block; /* 让图片成为块级元素 */
            margin: 0 auto; /* 设置左右外边距为自动 */
      }
      .body-text {
          font-size: 18px; /* 设置文字大小 */
          font-family: "Arial", sans-serif; /* 设置字体 */
          font-weight: bold; /* 设置字体加粗（可选） */
          color: #333; /* 设置文字颜色 */
          padding-top: 10px;
          text-align: center;
      }
      .author-text {
          font-size: 20px; /* 设置文字大小 */
          font-family: "Arial", sans-serif; /* 设置字体 */
          color: #333; /* 设置文字颜色 */
          text-align: center; /* 水平居中对齐 */
          padding-top: 25px;
      }
      .tag-container {
            text-align: center;
            position: relative; /* 相对定位，用于设置内部元素位置 */
            display: inline-block; /* 保证文字和标签紧凑 */
      }

      .tag {
            position: absolute; /* 绝对定位，让标签浮动在文字上方 */
            top: -10px; /* 控制标签距离文字的高度 */
            left: 100%; /* 水平居中 */
            transform: translateX(-50%); /* 调整标签的中心点 */
            color: #a01818; /* 标签文字颜色 */
            font-size: 12px; /* 标签文字大小 */
            padding: 2px 6px; /* 标签内边距 */
            border-radius: 4px; /* 标签圆角 */
        }
      .center-div {
            font-size: 20px; /* 设置文字大小 */
            font-family: "Arial", sans-serif; /* 设置字体 */
            width: 100%; /* 设置宽度 */
            margin: 0 auto; /* 水平居中 */
            color: white;
            padding: 0px;
            text-align: center;
        }
        .line {
            border-top: 2px solid #000000; /* 设置上边框为2px粗的红色线条 */
            width: 95%; /* 设置线条宽度 */
            margin: 20px auto; /* 设置上下间距，居中显示 */
        }
      .body-div {
            font-family: "Arial", sans-serif; /* 设置字体 */
            width: 90%; /* 设置宽度 */
            margin: 0 auto; /* 水平居中 */
            padding: 0px;
/*             text-align: center; */
      }

      body {
          font-family: Arial, sans-serif;
          padding: 20px;
      }
      table {
          width: 95%;
          margin: 0 auto; /* 水平居中 */
          border-collapse: collapse;
          margin-bottom: 20px;
      }
      table, th, td {
          border: 1px solid #ddd;
      }
      th, td {
          padding: 8px 12px;
          /* text-align: center; */
      }
      th {
          background-color: #f2f2f2;
      }
      section {
          padding: 10px;
          width: 93%;
          margin-bottom: 0px;
          margin: 0 auto; /* 水平居中 */
          border: 1px solid #ddd;
          background-color: #f9f9f9;
          
      }
      section h2 {
          color: #333;
          
      }
      b {
            color: rgb(34, 138, 218); /* 默认链接颜色 */
            text-decoration: none; /* 去掉下划线 */
            font-weight: bold; /* 设置字体加粗（可选） */
      }

      a {
            color: rgb(13, 68, 111); /* 默认链接颜色 */
            text-decoration: none; /* 去掉下划线 */
            font-weight: bold; /* 设置字体加粗（可选） */
      }
      a:hover {
          text-decoration: underline;
      }
      ol{
        font-size: 24px;
        font-weight: bold; /* 设置字体加粗（可选） */
      }

    </style>
</head>
<body>
    <!-- 主标题 -->

    <header>
        <h1 class="custom-text">SimLabel: Consistency Guided OOD Detection with Pretrained Vision-Language Models</h1>
        <br>
        <div class="center-div">
          <a href="https://openreview.net/profile?id=~Shu_Zou1" target="_blank">ShuZou,</a><span style="color:red"><sup>1</sup></span>
          <a href="https://scholar.google.com/citations?user=hg_nsIcAAAAJ&hl=en" target="_blank">XinyuTian,</a><span style="color:red"><sup>1</sup></span>
          <a href="https://scholar.google.com.hk/citations?user=2-QO-bYAAAAJ&hl=zh-CN" target="_blank">QinyuZhao,</a><span style="color:red"><sup>1</sup></span>
          <a href="https://scholar.google.com/citations?user=qxa04lIAAAAJ&hl=en" target="_blank">ZhaoyuanYang,</a><span style="color:red"><sup>2</sup></span>
          <a href="https://scholar.google.com.au/citations?user=Qa1DMv8AAAAJ&hl=en" target="_blank">JingZhang</a><span style="color:red"><sup>1</sup></span>
        </div>
        <div class="body-div">
          <h2 class="body-text">
          1.The Australian National University     2.GE Research</h2>
        </div>


        <div class="line"></div>
        <div class="body-div">
          <h2 class="body-text">
          This is the demostration page for TCSVT sumbission: SimLabel: Consistency Guided OOD Detection with Pretrained Vision-Language Models, a consistency-based method
          aiming on enhancing zero-shot OOD detection task with pre-trained Vision-Language models.  We hope you could enjoy our demonstartion and hope
          this page makes it easy for you to understand the paper.</h2>
        </div>
        <br>
        <div class="line"></div>

    </header>

    <!-- 主内容区域 -->
    <main>
      <!-- 表格 -->
      <table>
          <thead>
              <tr>
                  <th>Sections</th>
              </tr>
          </thead>
          <tbody>
              <tr>
                <td><a href="https://github.com/ShuZou-1/SimLabel/tree/main" target="_blank">Project Link</a></td>
              </tr>              
              <tr>
                <td><a href="#section0">Demonstartion of how SimLabel Correct MCM  </a></td>
                </tr>
              <tr>
                  <td><a href="#section1">Preliminary</a></td>
              </tr>
              <tr>
                  <td><a href="#section2">Motivation</a></td>
              </tr>
              <tr>
                <td><a href="#section3">Similar Class Generation</a></td>
             </tr>
              <tr>
                  <td><a href="#section4">Overview of Pipeline</a></td>
              </tr>
              <tr>
                <td><a href="#section5">Score Design</a></td>
            </tr>              
            <tr>
                <td><a href="#section6">Experiment Details</a></td>
            </tr>   
            <tr>
                <td><a href="#section7">Reference</a></td>
            </tr>               
          </tbody>
      </table>
 
      <section id="section0">
        <h2 class="custom-text">Demostration of how SimLabel Correct Prediction</h2>
        <p> We presents this figure demostrating two practical examples illustrating how our proposed SimLabel score improves OOD detection compared to the MCM baseline. In these examples, SimLabel successfully identifies the OOD images by leveraging their poor consistency with the similar classes:</p>
        <img src="./images/demostration.png" alt="示例图片" width="600"/>

      </section>
      <!-- Section 1 -->
      <section id="section1">
        <h2 class="custom-text">Preliminary</h2>
        <img src="./images/prelimilaries.png" alt="示例图片" width="600"/>
        
      </section>
  
      <!-- Section 2 -->
      <section id="section2">
          <h2 class="custom-text">Motivation</h2>
          <p>This study is motivated by the identification of a critical yet often overlooked issue: the ID image-text similarity score serves as an useful indicator in explainingthe intrinsic connections among different classes. We firstly show a simple while intuitive example for how using consistency demostrating the motivation:
            </p>
            <img src="./images/consistency_OOD_demo.png" alt="示例图片" width="600"/>
            <p> Given ID (top) and OOD (bottom) images which are predicted as the same class by the baseline method, ID images show consistent higher similarity to the set of semantically similar ID classes than OOD images. </p>
            <p>
            In order to dig the existence of similar classes, we also design a
            straightforward experiment to explore the existence of similar classes. Given a batch of images from ID dataset where their ground-truth are all the same, we calculate the average similarity between the images and each text label.The sorted similarity distribution is visualized as following: </p>
            <img src="./images/motivation_longtail.png" alt="示例图片" width="600" />
            <p>where they generally exhibit high similarity to a small subset of ID labels, including but not limited to the ground truth label.This finding underscores the presence of similar classes, highlighting inherent connections among ID labels.</p>
            
      </section>
  
      <!-- Section 3 -->


      <section id="section3">
        <h2 class="custom-text">Similar Classes Generation</h2>
        <ol>
            <li>Generation with Class-Hierarchy</li><img src="./images/hierarchy.png" alt="示例图片" width="450" />
            <li>Generation with LLMs (GPT-4)</li> 
            <li>Generation with image-text alignment</li>
            <img src="./images/algorithm.png" alt="示例图片" width="600" />
        </ol>
        Here we provide examples in similar classes generated by LLM and image-text alignment.
        <img src="./images/example.png" alt="示例图片" width="600" />
       </section>

       <section id="section4">
        <h2 class="custom-text">Overview pipeline of SimLabel</h2>
        <img src="./images/pipeline.png" alt="示例图片" width="600" />
    </section>
    <section id="section5">
        <h2 class="custom-text">Score Design</h2>
        <p>Given a image and corresponding ID similar classes, we can obtain the affinity with</p>
        <img src="./images/affinity.png" alt="示例图片" width="600" />
        <p>where the "||" represents the cardinality of similar classes and the alpha represents the hyper-parameter that determines the weight of image&similar-classes-label similarity.Motivated by the assumption in[2] that the maximum similarity of ID image-text alignment shows advantages over OOD samples, we formally define our SimLabel score with the maximum matching score as:</p>
        <img src="./images/softmax.png" alt="示例图片" width="600"/>
    </section>

    <section id="section6">
        <h2 class="custom-text">Experiment Details</h2>
        <p>We evaluate our method on the ImageNet-1k OOD benchmark and primarily compare it with the MCM method due to its promising and consistent performance in the zero-shot OOD detection task. The ImageNet-1k OOD benchmark is a widely used performance validation method that uses the large-scale visual dataset ImageNet-1k as ID data and iNaturalist, SUN, Places, and Texture as OOD data, covering a diverse range of scenes and semantics. Each OOD dataset has no classes that overlap with the ID dataset.In our experiments, we adopt CLIP[1] as the target pre-trained model, which is one of the most popular and publicly available VLMs.For selecting similar classes in SimLabel-H, we follow the construction of hierarchical label sets in[3]to obtain accurate super-classes for the ImageNet labels and generate similar classes.The LLMs we prompt for SimLabel-L is GPT-4.n generating similar classes for SimLabel-L and SimLabel-I score, we select the quantity of similar classes k=6.Additionally, following the theoretical analysis and setting in[2], we set temperature tau = 1. We set the weight of image \& similar-classes-label alpha = 1. All experiments are conducted on a single NVIDIA 4090 GPU.</p>
    </section>    

    <section id="section7">
        <h2 class="custom-text">Reference</h2>
        <ol>
            <li>Radford A, Kim J W, Hallacy C, et al. Learning transferable visual models from natural language supervision[C]//International conference on machine learning. PMLR, 2021: 8748-8763.</li>
            <li>Ming Y, Cai Z, Gu J, et al. Delving into out-of-distribution detection with vision-language representations[J]. Advances in neural information processing systems, 2022, 35: 35087-35102.</li> 
            <li>Novack Z, McAuley J, Lipton Z C, et al. Chils: Zero-shot image classification with hierarchical label sets[C]//International Conference on Machine Learning. PMLR, 2023: 26342-26362.</li>
        </ol>     
    </section>  

    </main>


    <script src="script.js"></script>
</body>
</html>
